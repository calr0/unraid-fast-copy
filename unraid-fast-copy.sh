#!/bin/bash

# The {share_name} and {share_subdir} variables define the
# name of the unraid share you want to copy as well as an 
# optional subdirectory path within the share if you want 
# to keep the copy scoped to one specific share folder.
# 
# The values below would copy the unraid share named "storage" in it's entirety to
# {target_path}/storage/
#    > share_name="storage"
#    > share_subdir=""
#
# These values would copy the "season 1" directory from the share named "media" 
# to this location in your {target_path}: {target_path}/media/tv/show name/season 1/
#    > share_name="media"
#    > share_subdir="tv/show name/season 1"
#    
# These values would copy the "tv" directory located in the "media" share
# to this location in your {target_path}: {target_path}/media/tv/
#    > share_name="media"
#    > share_subdir="tv"
#
# If {share_subdir} is defined, it must be relative to the root 
# of the share, and can not have a leading or trailing slash in the path
share_name="media"
share_subdir="tv"

# The {target_path} variable defines the location that you'll want the unraid share copied to.
#
# The media folder will be coped directly into the target dir, creating this structure:
#     {target_path}/{share_name}/
#
# Or if share_subdir was defined, it'd look like this:
#     {target_path}/{share_name}/{share_subdir}
#
# In either case, the directories will be fully copied and
# preserved exactly as they appeared in the unraid share.
# Any directories that don't exist on the {target_path} will
# automatically be created.
#
# This path is passed directly to rsync so you should also be able to define it as a remote path.
# So far i've only tested it by setting it to the path of nfs/smb network share mounted on the unraid server.
target_path="/mnt/cifs-or-nfs/mounted/network/share"

# The {source_path} defines the location that the user shares are mounted in unraid.
# This is the default path for user share mounts and shouldn't have to be updated.
source_path="/mnt/user/"

# Defines the location that all temp output
# files will be generated by the script
script_output_dir="$(pwd)/output"

# Defines whether or not the script should automatically delete all of the files it created when the script completes.
# The default is 'no' because many of the rsync files (input files, stdout redirected to a file, logfile) will be in
# there and can be useful to review during/after the transfer for general stats/info about the run. Changing this value
# to 'yes' will enable the cleanup functionality on script exit.
#
# Note: if you rerun this script, it will always clean out temp data from past runs when it starts.
# This cleanup option only defines whether or not it should delete temp files when the script exits.
cleanup='no'


setup_env() {
    echo "Setting up script enviornment"
    if [[ -d "$script_output_dir" ]]; then
        # if the script's output dir already exists just
        # delete any old output files from previous runs
        echo "Deleting temp files generated from past runs"
        rm -rvf "$script_output_dir"/*.*
    else
        echo "Creating directory for temp script files"
        mkdir -v "$script_output_dir"
    fi
}


cleanup_env() {
    # if the cleanup parameter is set to 'yes'
    # the script's output directory will be deleted
    if [[ $cleanup == yes ]]; then
        echo "Cleaning up script environment"
        if [[ -d "$script_output_dir" ]]; then
            rm -vrf "$script_output_dir"
        fi
    fi
}


terminate() {
    printf "\n\nCaught termination signal, killing child rsync processes...\n"
    # block SIGTERM so it doesn't interfere with killing child rsync 
    # processes, then kill all child processes and exit this script
    trap "" SIGTERM
    kill 0 
    cleanup_env
    exit
}


generate_disk_directory_listings() {
    # generate a listing of all directories on each disk that belong to the specifified share name.
    # this listing will be scoped to the specific share subdirectory path if one was specified.
    for disk_mount_path in $(find /mnt/disk* -type d -maxdepth 0 | sort -t "/" -hk 3.5,3); do
        disk_name=${disk_mount_path//"/mnt/"/}
        dir_listing_file="$script_output_dir/$disk_name-listing.txt"
        
        # find all leaf directory paths in the unraid share.
        # if any paths are found, redirect to listing file.
        pushd "$disk_mount_path" > /dev/null
        echo "Generating share directory listing for $disk_name"
        find "$share_name/$share_subdir" -type d -links 2 -printf "$disk_name\t%p\n" 2>/dev/null | sort > "$dir_listing_file"
        popd > /dev/null

        # if we didn't find anything on this 
        # disk delete the empty listing file
        if [[ ! -s "$dir_listing_file" ]]; then
            rm "$dir_listing_file"
        fi
    done
}


copy_unraid_share() {
    # first we'll want to make sure we trap any SIGINT or SIGTEM signals so that either of 
    # those can be poperly handled by killing any child processes that are spawned below. 
    trap terminate SIGINT SIGTERM

    # for each file containing the complete listing of the share data on each disk:
    #   1. convert the file to an input file that can be passed directly to rsync
    #   2. spawn a child rsync process to copy the from each of the disks. this copy is 
    #      done from the share's user mount location, rather than from the disk's mount
    #      just for some added safety.

    for dir_listings_file in $(find "$script_output_dir" -name disk*-listing.txt); do
        disk_id=$( [[ ${dir_listings_file} =~ .*disk([0-9]+)-listing.txt ]] && echo "${BASH_REMATCH[1]}" )
        rsync_file_basename="$script_output_dir"/rsync-"$disk_id"
        rm -vf "$rsync_file_basename.*"
        
        # Convert the disk's share directory listing file to
        # an input file that can be passed directly to rsync
        echo "Generating rsync input files for disk $disk_id"
        cat "$dir_listings_file" | while IFS=$'\t' read disk_name dir_path; do
            echo "/$dir_path/" >> "$rsync_file_basename.in"
        done

        # Spawn a child rsync process to copy the data that lives on a single disk.
        # this process will run in the background, but progress can be seen by viewing
        # the .log and .out files. There will be a pair of .log and .out files per rsync
        # process. 
        #
        # The .out file will contain the overall progress of that individual
        # process and the stats per directory it's copied so far as well as an average 
        # read speed and ETA for the total copy for the data on the disk it's copying from. 
        # The .log file will contain a less verbose set of operations rsync is doing. 
        # 
        # The list of args below are what I found to be most efficient. With an array 
        # of 12 disks total (2 for parity, 10 for data) I was able to get a consistent
        # read rate of ~700MB/s and roughtly the same outbound network speeds when copying
        # to a locally mounted cifs network share.
        # 
        # My use-case was also not to use rsync to synchonize any data across machines,
        # only for a one time copy of the data. I chose to use rsync because of it's 
        # flexibility. There's no reason something simpler like `cp` couln't be used
        # in it's place if the location you're copying to is mounted locally.
        
        echo "Starting rsync process for disk $disk_id..."
        {
            stdbuf -oL \
            rsync -vv \
                  --progress \
                  --human-readable=3 \
                  --info=progress2,flist3,stats3 \
                  --log-file-format="%o=%-7'''b | total=%-7'''l [%i] => %f%L" \
                  --log-file="$rsync_file_basename.log" \
                  --max-alloc=8GiB \
                  --whole-file \
                  --inplace \
                  --sparse \
                  --no-compress \
                  --size-only \
                  --files-from="$rsync_file_basename.in" \
                  "$source_path" \
                  "$target_path" \
            | tee "$rsync_file_basename.out" >/dev/null
        } &
    done 

    # once all rsync processes have been spawned, wait for 
    # all of them to complete before exiting. Ctrl + C can 
    # be used to terminate the script early and terminate 
    # all child rsync processes that are still active
    echo "Waiting for rsync child processes to complete..."
    wait

}

setup_env
generate_disk_directory_listings
copy_unraid_share
cleanup_env